{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZDsOC8WZx24"
      },
      "source": [
        "# **Retrival**\n",
        "\n",
        "In LangChain, retrieval refers to the process of accessing and fetching relevant pieces of information from a collection of documents or data sources based on a query. This involves using techniques like similarity search and embedding-based methods to find and return the most pertinent documents or text segments that match the query's context and content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyhmxkE1YbWo"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# update or install the necessary libraries\n",
        "!pip install --upgrade langchain langchain_community langchain_aws pypdf tiktoken chromadb lark python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 847
        },
        "id": "I2gfpVmPO3K6",
        "outputId": "a7380db9-f1e6-44e3-8dd0-932d43c3f60a"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y numpy pandas\n",
        "!pip install --no-cache-dir numpy==1.26.4 pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmhrM0gQohMS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
        "os.environ[\"AWS_DEFAULT_REGION\"] = os.getenv(\"AWS_DEFAULT_REGION\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD-yLJRYYkgW"
      },
      "source": [
        "# **Vectorstore retrieval**\n",
        "\n",
        "Vectorstore retrieval is a technique that involves storing and retrieving data using vector representations of text. It enables efficient similarity searches by converting text into high-dimensional vectors and then finding the closest vectors in the database. This method is particularly useful for applications requiring fast and accurate information retrieval based on semantic similarity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDKCuVkvbmFZ"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# Load PDF\n",
        "loaders = [\n",
        "    # Duplicate documents on purpose - messy data\n",
        "    PyPDFLoader(\"./content/MachineLearning-Lecture01.pdf\"),\n",
        "    PyPDFLoader(\"./content/MachineLearning-Lecture02.pdf\"),\n",
        "    PyPDFLoader(\"./content/MachineLearning-Lecture03.pdf\")\n",
        "\n",
        "]\n",
        "docs = []\n",
        "for loader in loaders:\n",
        "    docs.extend(loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZdCG2EYbnD6",
        "outputId": "568df721-5763-4821-f191-0366501213a9"
      },
      "outputs": [],
      "source": [
        "# Split\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1500,\n",
        "    chunk_overlap = 150\n",
        ")\n",
        "\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "len(splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojzmOu7OoyNm"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "persist_directory = 'docs/chroma/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja6dCyY1pEGQ"
      },
      "outputs": [],
      "source": [
        "from langchain_aws import BedrockEmbeddings\n",
        "\n",
        "embedding = BedrockEmbeddings(\n",
        "    model_id=\"amazon.titan-embed-text-v2:0\"\n",
        ")\n",
        "\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H22zqjeWpYef",
        "outputId": "2aa2b80d-27dd-4376-ec1b-2d114324044e"
      },
      "outputs": [],
      "source": [
        "vectordb._collection.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-SK9rxSpc2V"
      },
      "outputs": [],
      "source": [
        "texts = [\n",
        "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
        "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
        "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALEQTlhCpgV_"
      },
      "outputs": [],
      "source": [
        "smalldb = Chroma.from_texts(texts, embedding=embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5M6a4hE3pgqO"
      },
      "outputs": [],
      "source": [
        "question = \"Tell me about all-white mushrooms with large fruiting bodies\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVd3L-5sYpln"
      },
      "source": [
        "# **Similarity Search**\n",
        "\n",
        "Similarity search is a method used to find items in a database that are most similar to a given query item based on certain criteria. It involves comparing vector representations of items and retrieving those with the smallest distance or highest similarity score. This approach is commonly used in applications like document retrieval, image matching, and recommendation systems.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAydVLibpgu1",
        "outputId": "b3170556-bcef-4492-fdf8-670a414c2018"
      },
      "outputs": [],
      "source": [
        "smalldb.similarity_search(question, k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gztlWTUsp3Iz",
        "outputId": "5af79a0e-c9a9-4e61-f4ad-f1cc7780f6f5"
      },
      "outputs": [],
      "source": [
        "smalldb.max_marginal_relevance_search(question,k=2, fetch_k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw97_yj2aili"
      },
      "source": [
        "## Addressing Diversity: Maximum marginal relevance\n",
        "\n",
        "Last class we introduced one problem: how to enforce diversity in the search results.\n",
        "\n",
        "`Maximum marginal relevance` strives to achieve both relevance to the query *and diversity* among the results.\n",
        "\n",
        "Maximum Marginal Relevance (MMR) is a technique used in information retrieval to enhance the diversity of search results. It aims to select documents that are not only relevant to a query but also diverse from each other. This diversity helps provide a broader perspective or coverage of the topic being queried.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIecO_wsZui6"
      },
      "outputs": [],
      "source": [
        "question = \"what did they say about matlab?\"\n",
        "docs_ss = vectordb.similarity_search(question,k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nlK1SP4aaqcG",
        "outputId": "4e71aa3d-9267-4aeb-cdc6-c6ee412903e6"
      },
      "outputs": [],
      "source": [
        "docs_ss[0].page_content[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "j-9TE7-_asd1",
        "outputId": "89938e10-7ffd-47f9-9bf4-a29b0e19007a"
      },
      "outputs": [],
      "source": [
        "docs_ss[1].page_content[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4C--BrRcnJJ"
      },
      "source": [
        "Note the difference in results with `MMR`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFsLht7Ucmbx"
      },
      "outputs": [],
      "source": [
        "docs_mmr = vectordb.max_marginal_relevance_search(question,k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vtbK71DucqzB",
        "outputId": "0f15e1b3-6c2f-4699-fe3e-8ddbd4b63ce6"
      },
      "outputs": [],
      "source": [
        "docs_mmr[0].page_content[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4Cmv6V5ucr_1",
        "outputId": "e380fe2d-f4e1-460e-ba02-0250cd584b27"
      },
      "outputs": [],
      "source": [
        "docs_mmr[1].page_content[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bIQyJjqcyGo"
      },
      "source": [
        "## **Addressing Specificity: working with metadata**\n",
        "\n",
        "In last lecture, we showed that a question about the third lecture can include results from other lectures as well.\n",
        "\n",
        "To address this, many vectorstores support operations on `metadata`.\n",
        "\n",
        "`metadata` provides context for each embedded chunk.\n",
        "\n",
        "Metadata filtering refers to the process of selectively retrieving or excluding data based on predefined metadata attributes or criteria. In the context of information retrieval systems like LangChain, metadata filtering allows users to narrow down search results by specifying metadata tags or attributes associated with documents or data chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyCYTYboctXP"
      },
      "outputs": [],
      "source": [
        "question = \"what did they say about regression in the third lecture?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnW9VfKJc2Uz"
      },
      "outputs": [],
      "source": [
        "docs = vectordb.similarity_search(\n",
        "    question,\n",
        "    k=3,\n",
        "    filter={\"source\":\"docs/cs229_lectures/MachineLearning-Lecture03.pdf\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMESrO2Zc3jk"
      },
      "outputs": [],
      "source": [
        "for d in docs:\n",
        "    d.metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZpSertVc_mi"
      },
      "source": [
        "## **Addressing Specificity: working with metadata using self-query retriever**\n",
        "\n",
        "But we have an interesting challenge: we often want to infer the metadata from the query itself.\n",
        "\n",
        "To address this, we can use `SelfQueryRetriever`, which uses an LLM to extract:\n",
        "\n",
        "1. The `query` string to use for vector search\n",
        "2. A metadata filter to pass in as well\n",
        "\n",
        "Most vector databases support metadata filters, so this doesn't require any new databases or indexes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daIJI8cSc48Z"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "from langchain_aws import BedrockLLM\n",
        "from langchain.chains.query_constructor.base import AttributeInfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mgSnmYidDWN"
      },
      "outputs": [],
      "source": [
        "metadata_field_info = [\n",
        "    AttributeInfo(\n",
        "        name=\"source\",\n",
        "        description=\"The lecture the chunk is from, should be one of `docs/cs229_lectures/MachineLearning-Lecture01.pdf`, `docs/cs229_lectures/MachineLearning-Lecture02.pdf`, or `docs/cs229_lectures/MachineLearning-Lecture03.pdf`\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"page\",\n",
        "        description=\"The page from the lecture\",\n",
        "        type=\"integer\",\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUov2iPZdF_J"
      },
      "outputs": [],
      "source": [
        "document_content_description = \"Lecture notes\"\n",
        "llm = BedrockLLM(\n",
        "    model_id=\"mistral.mistral-7b-instruct-v0:2\",\n",
        "    temperature=0.7,\n",
        ")\n",
        "retriever = SelfQueryRetriever.from_llm(\n",
        "    llm,\n",
        "    vectordb,\n",
        "    document_content_description,\n",
        "    metadata_field_info,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXHu75E_dLRx"
      },
      "outputs": [],
      "source": [
        "question = \"what did they say about regression in the third lecture?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBlr6jzNda58"
      },
      "source": [
        "**You will receive a warning** about predict_and_parse being deprecated the first time you executing the next line. This can be safely ignored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Sdl8kDRdaVf",
        "outputId": "22e3a7e5-1317-4e6d-e458-96da9716c70a"
      },
      "outputs": [],
      "source": [
        "docs = retriever.get_relevant_documents(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3r6AeRp5ddtO"
      },
      "outputs": [],
      "source": [
        "for d in docs:\n",
        "    d.metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TjRj-23dzcX"
      },
      "source": [
        "## **Additional tricks: compression**\n",
        "\n",
        "Another approach for improving the quality of retrieved docs is compression.\n",
        "\n",
        "Information most relevant to a query may be buried in a document with a lot of irrelevant text.\n",
        "\n",
        "Passing that full document through your application can lead to more expensive LLM calls and poorer responses.\n",
        "\n",
        "Contextual compression is meant to fix this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdWqgzQUdgD2"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EeUfJS_d2Ok"
      },
      "outputs": [],
      "source": [
        "def pretty_print_docs(docs):\n",
        "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LIo3aO9d3T9"
      },
      "outputs": [],
      "source": [
        "# Wrap our vectorstore\n",
        "llm = BedrockLLM(\n",
        "    model_id=\"mistral.mistral-7b-instruct-v0:2\",\n",
        "    temperature=0.7,\n",
        ")\n",
        "compressor = LLMChainExtractor.from_llm(llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4U8aNmNTd7MV"
      },
      "outputs": [],
      "source": [
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=vectordb.as_retriever()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyAK28F2d8ja",
        "outputId": "e5c9f3cc-8473-43f9-d151-4d823ff966a7"
      },
      "outputs": [],
      "source": [
        "question = \"what did they say about matlab?\"\n",
        "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
        "pretty_print_docs(compressed_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsmkyBr6eBpd"
      },
      "source": [
        "# **Combining various techniques**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CDG99iTd9k7"
      },
      "outputs": [],
      "source": [
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=vectordb.as_retriever(search_type = \"mmr\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5n6DowTeFVs",
        "outputId": "7c157940-618c-4442-eef0-6499dc7c1428"
      },
      "outputs": [],
      "source": [
        "question = \"what did they say about matlab?\"\n",
        "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
        "pretty_print_docs(compressed_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyR-CLONeJ3J"
      },
      "source": [
        "# **Other types of retrieval**\n",
        "\n",
        "It's worth noting that vectordb as not the only kind of tool to retrieve documents.\n",
        "\n",
        "The `LangChain` retriever abstraction includes other ways to retrieve documents, such as TF-IDF or SVM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGnmxnyDeGnR"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import SVMRetriever\n",
        "from langchain.retrievers import TFIDFRetriever\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAAwmUazeMoN"
      },
      "outputs": [],
      "source": [
        "# Load PDF\n",
        "loader = PyPDFLoader(\"./content/MachineLearning-Lecture01.pdf\")\n",
        "pages = loader.load()\n",
        "all_page_text=[p.page_content for p in pages]\n",
        "joined_page_text=\" \".join(all_page_text)\n",
        "\n",
        "# Split\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,chunk_overlap = 150)\n",
        "splits = text_splitter.split_text(joined_page_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iT2vMH8peQrN"
      },
      "outputs": [],
      "source": [
        "# Retrieve\n",
        "svm_retriever = SVMRetriever.from_texts(splits,embedding)\n",
        "tfidf_retriever = TFIDFRetriever.from_texts(splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS386Lk6eSpN",
        "outputId": "611a1c14-6397-498d-82dc-975287e68e25"
      },
      "outputs": [],
      "source": [
        "question = \"What are major topics for this class?\"\n",
        "docs_svm=svm_retriever.get_relevant_documents(question)\n",
        "docs_svm[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BI9uxgteUZx",
        "outputId": "ddc21e95-a3f8-4b03-c781-788886485ea5"
      },
      "outputs": [],
      "source": [
        "question = \"what did they say about matlab?\"\n",
        "docs_tfidf=tfidf_retriever.get_relevant_documents(question)\n",
        "docs_tfidf[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRmZkqrCe0hg"
      },
      "source": [
        "# **Let's Do an Activity**\n",
        "\n",
        "## **Objective**\n",
        "\n",
        "Explore different retrieval techniques in LangChain to fetch relevant documents based on queries.\n",
        "\n",
        "## **Scenario**\n",
        "\n",
        "You are building a document retrieval system for a research library. This activity will help you understand and implement various retrieval methods to efficiently fetch documents related to specific topics or queries.\n",
        "\n",
        "## **Steps**\n",
        "\n",
        "* Load Documents\n",
        "* Embedding and Vector Store\n",
        "* Similarity Search\n",
        "* Maximum Marginal Relevance (MMR)\n",
        "* Metadata Filtering\n",
        "* Alternative Retrieval Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDANj1w7eWUQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

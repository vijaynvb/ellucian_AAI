{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "78ec6921",
      "metadata": {
        "id": "78ec6921"
      },
      "source": [
        "# Agents\n",
        "\n",
        "Agent is a modular and flexible component that can perform a variety of tasks by leveraging multiple tools and large language models (LLMs). Agents act as intermediaries that can dynamically select and execute actions based on the input they receive. They enable the creation of complex applications that require decision-making and multi-step processes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kqJcOL4F-3pK",
      "metadata": {
        "id": "kqJcOL4F-3pK"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# update or install the necessary libraries\n",
        "!pip install --upgrade openai\n",
        "!pip install --upgrade langchain\n",
        "!pip install --upgrade langchain_community\n",
        "!pip install --upgrade langchain_openai\n",
        "!pip install --upgrade langchainhub\n",
        "!pip install --upgrade tavily-python\n",
        "!pip install --upgrade python-dotenv\n",
        "# !pip install --upgrade langchain_aws"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TCOvsI_wQTm4",
      "metadata": {
        "id": "TCOvsI_wQTm4"
      },
      "source": [
        "TavilySearchResults is a valuable tool that connects your language model (LLM) to the web using the Tavily Search API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b2421f4",
      "metadata": {
        "id": "7b2421f4"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import hub\n",
        "from langchain.agents import create_openai_functions_agent\n",
        "from langchain.agents import AgentExecutor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d5efcf4",
      "metadata": {
        "id": "4d5efcf4"
      },
      "source": [
        "## Prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "czP2CER6EEt4",
      "metadata": {
        "id": "czP2CER6EEt4"
      },
      "source": [
        "**LangChain Hub**\n",
        "\n",
        "Efficiently manage your LLM components with the LangChain Hub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5992682a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5992682a",
        "outputId": "a926c595-b9d1-42d7-bf08-21b10f467a52"
      },
      "outputs": [],
      "source": [
        "# Get the prompt to use - you can modify this!\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3716d768",
      "metadata": {
        "id": "3716d768"
      },
      "source": [
        "## LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30acf78d",
      "metadata": {
        "id": "30acf78d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0,openai_api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1a1ece2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "# from dotenv import load_dotenv\n",
        "\n",
        "# # Load environment variables from .env file\n",
        "# load_dotenv()\n",
        "\n",
        "# os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
        "# os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
        "# os.environ[\"AWS_DEFAULT_REGION\"] = os.getenv(\"AWS_DEFAULT_REGION\")\n",
        "\n",
        "# llm = ChatBedrock(\n",
        "#     model_id=\"claude-3.5-sonnet-update this value from bedrock\",\n",
        "#     temperature=0,\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3fd4cf9",
      "metadata": {
        "id": "a3fd4cf9"
      },
      "source": [
        "## Tools\n",
        "\n",
        "Tavily's Search API is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.\n",
        "\n",
        "Generate Tavily API Key from this [link](https://app.tavily.com/home)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32a2c52f",
      "metadata": {
        "id": "32a2c52f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZfoaRX0GC4T3",
      "metadata": {
        "id": "ZfoaRX0GC4T3"
      },
      "outputs": [],
      "source": [
        "search = TavilySearchResults()\n",
        "tools = [search]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7daee658",
      "metadata": {
        "id": "7daee658"
      },
      "source": [
        "## Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6152ad4",
      "metadata": {
        "id": "b6152ad4"
      },
      "outputs": [],
      "source": [
        "agent = create_openai_functions_agent(llm, tools, prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df123904",
      "metadata": {
        "id": "df123904"
      },
      "outputs": [],
      "source": [
        "result = agent.invoke({\"input\": \"what's the weather in SF?\", \"intermediate_steps\": []})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbf7ceb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fbf7ceb5",
        "outputId": "b3607185-1ae3-4c85-f16a-a847ca6707d1"
      },
      "outputs": [],
      "source": [
        "result.tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee380cf3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee380cf3",
        "outputId": "e9f3a195-6168-46da-97a6-6abbb967af77"
      },
      "outputs": [],
      "source": [
        "result.tool_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55f14f30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55f14f30",
        "outputId": "d7f2f869-cdb1-4d98-db6f-f57cbc574345"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87a3993e",
      "metadata": {
        "id": "87a3993e"
      },
      "source": [
        "## Agent Executor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eef3db8",
      "metadata": {
        "id": "2eef3db8"
      },
      "outputs": [],
      "source": [
        "agent_executor = AgentExecutor(agent=agent, tools=tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6c08822",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6c08822",
        "outputId": "320e7631-3436-44a6-b75a-2e7d1dc5b01b"
      },
      "outputs": [],
      "source": [
        "agent_executor.invoke({\"input\": \"what is the weather in sf?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e8ca119",
      "metadata": {
        "id": "4e8ca119"
      },
      "source": [
        "## Streaming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9b9dd6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9b9dd6e",
        "outputId": "236fe59e-3974-4c69-e0da-c6dc9853a302"
      },
      "outputs": [],
      "source": [
        "for step in agent_executor.stream({\"input\": \"what is the weather in sf?\"}):\n",
        "    print(step)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-d_DefWbTDVM",
      "metadata": {
        "id": "-d_DefWbTDVM"
      },
      "source": [
        "# **Let's Do an Activity**\n",
        "\n",
        "## **Objective**\n",
        "\n",
        "Creating an Agent with Tavily Search and OpenAI for Real-Time Information Retrieval\n",
        "\n",
        "## **Scenario**\n",
        "\n",
        "How can you create a LangChain agent that utilizes Tavily's Search API to retrieve real-time information and generate responses using OpenAI's GPT-3.5-turbo model?\n",
        "\n",
        "## **Steps**\n",
        "\n",
        "* Initialize API Keys\n",
        "* Import Required Libraries\n",
        "\n",
        "  * Import the necessary libraries from LangChain, LangChain Community, and OpenAI.\n",
        "\n",
        "* Configure the LLM\n",
        "\n",
        "  * Set up the ChatOpenAI model with your OpenAI API key.\n",
        "\n",
        "* Set Up Tavily Search\n",
        "\n",
        "  * Initialize the Tavily Search tool with your Tavily API key.\n",
        "\n",
        "* Create a Prompt Template\n",
        "* Create the Agent\n",
        "* Invoke the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba35f057",
      "metadata": {
        "id": "ba35f057"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
